{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using custom containers with AI Platform Training\n",
    "\n",
    "**Learning Objectives:**\n",
    "1. Learn how to create a train and a validation split with Big Query\n",
    "1. Learn how to wrap a machine learning model into a Docker container and train in on CAIP\n",
    "1. Learn how to use the hyperparameter tunning engine on GCP to find the best hyperparameters\n",
    "1. Learn how to deploy a trained machine learning model GCP as a rest API and query it\n",
    "\n",
    "In this lab, you develop, package as a docker image, and run on **AI Platform Training** a training application that trains a multi-class classification model that predicts the type of forest cover from cartographic data. The [dataset](../../../datasets/covertype/README.md) used in the lab is based on **Covertype Data Set** from UCI Machine Learning Repository.\n",
    "\n",
    "The training code uses `scikit-learn` for data pre-processing and modeling. The code has been instrumented using the `hypertune` package so it can be used with **AI Platform** hyperparameter tuning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import uuid\n",
    "import time\n",
    "import tempfile\n",
    "\n",
    "from googleapiclient import discovery\n",
    "from googleapiclient import errors\n",
    "\n",
    "from google.cloud import bigquery\n",
    "from jinja2 import Template\n",
    "from kfp.components import func_to_container_op\n",
    "from typing import NamedTuple\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure environment settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set location paths, connections strings, and other environment settings. Make sure to update   `REGION`, and `ARTIFACT_STORE`  with the settings reflecting your lab environment. \n",
    "\n",
    "- `REGION` - the compute region for AI Platform Training and Prediction\n",
    "- `ARTIFACT_STORE` - the GCS bucket created during installation of AI Platform Pipelines. The bucket name starts with the `hostedkfp-default-` prefix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://artifacts.mlops-dev-env.appspot.com/\n",
      "gs://hostedkfp-default-36un4wco1q/\n",
      "gs://jk-mlops-dev-sandbox/\n",
      "gs://mlops-dev-env-staging/\n",
      "gs://mlops-dev-env_cloudbuild/\n",
      "gs://mlops-dev-workspace/\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "REGION = 'us-central1'\n",
    "ARTIFACT_STORE = 'gs://mlops-dev-env-staging'\n",
    "\n",
    "PROJECT_ID = !(gcloud config get-value core/project)\n",
    "PROJECT_ID = PROJECT_ID[0]\n",
    "DATA_ROOT='{}/data'.format(ARTIFACT_STORE)\n",
    "JOB_DIR_ROOT='{}/jobs'.format(ARTIFACT_STORE)\n",
    "TRAINING_FILE_PATH='{}/{}/{}'.format(DATA_ROOT, 'training', 'dataset.csv')\n",
    "VALIDATION_FILE_PATH='{}/{}/{}'.format(DATA_ROOT, 'validation', 'dataset.csv')\n",
    "\n",
    "BQ_DATASET_NAME = 'data_validation'\n",
    "BQ_TABLE_NAME = 'covertype_classifier_logs'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the Covertype dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Elevation</th>\n",
       "      <th>Aspect</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Horizontal_Distance_To_Hydrology</th>\n",
       "      <th>Vertical_Distance_To_Hydrology</th>\n",
       "      <th>Horizontal_Distance_To_Roadways</th>\n",
       "      <th>Hillshade_9am</th>\n",
       "      <th>Hillshade_Noon</th>\n",
       "      <th>Hillshade_3pm</th>\n",
       "      <th>Horizontal_Distance_To_Fire_Points</th>\n",
       "      <th>Wilderness_Area</th>\n",
       "      <th>Soil_Type</th>\n",
       "      <th>Cover_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2085</td>\n",
       "      <td>256</td>\n",
       "      <td>18</td>\n",
       "      <td>150</td>\n",
       "      <td>27</td>\n",
       "      <td>738</td>\n",
       "      <td>176</td>\n",
       "      <td>248</td>\n",
       "      <td>208</td>\n",
       "      <td>914</td>\n",
       "      <td>Cache</td>\n",
       "      <td>C2702</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2125</td>\n",
       "      <td>256</td>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "      <td>12</td>\n",
       "      <td>871</td>\n",
       "      <td>169</td>\n",
       "      <td>248</td>\n",
       "      <td>215</td>\n",
       "      <td>300</td>\n",
       "      <td>Cache</td>\n",
       "      <td>C2702</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2146</td>\n",
       "      <td>256</td>\n",
       "      <td>34</td>\n",
       "      <td>150</td>\n",
       "      <td>62</td>\n",
       "      <td>1253</td>\n",
       "      <td>122</td>\n",
       "      <td>237</td>\n",
       "      <td>239</td>\n",
       "      <td>511</td>\n",
       "      <td>Cache</td>\n",
       "      <td>C2702</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2186</td>\n",
       "      <td>256</td>\n",
       "      <td>38</td>\n",
       "      <td>210</td>\n",
       "      <td>102</td>\n",
       "      <td>1294</td>\n",
       "      <td>109</td>\n",
       "      <td>232</td>\n",
       "      <td>244</td>\n",
       "      <td>552</td>\n",
       "      <td>Cache</td>\n",
       "      <td>C2702</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2831</td>\n",
       "      <td>256</td>\n",
       "      <td>25</td>\n",
       "      <td>277</td>\n",
       "      <td>183</td>\n",
       "      <td>1706</td>\n",
       "      <td>153</td>\n",
       "      <td>246</td>\n",
       "      <td>225</td>\n",
       "      <td>1485</td>\n",
       "      <td>Commanche</td>\n",
       "      <td>C2705</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>3136</td>\n",
       "      <td>254</td>\n",
       "      <td>12</td>\n",
       "      <td>319</td>\n",
       "      <td>60</td>\n",
       "      <td>5734</td>\n",
       "      <td>193</td>\n",
       "      <td>248</td>\n",
       "      <td>193</td>\n",
       "      <td>2467</td>\n",
       "      <td>Rawah</td>\n",
       "      <td>C7746</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>3242</td>\n",
       "      <td>254</td>\n",
       "      <td>12</td>\n",
       "      <td>636</td>\n",
       "      <td>148</td>\n",
       "      <td>3551</td>\n",
       "      <td>193</td>\n",
       "      <td>248</td>\n",
       "      <td>193</td>\n",
       "      <td>2010</td>\n",
       "      <td>Commanche</td>\n",
       "      <td>C7757</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>2071</td>\n",
       "      <td>255</td>\n",
       "      <td>12</td>\n",
       "      <td>234</td>\n",
       "      <td>63</td>\n",
       "      <td>342</td>\n",
       "      <td>192</td>\n",
       "      <td>247</td>\n",
       "      <td>193</td>\n",
       "      <td>247</td>\n",
       "      <td>Cache</td>\n",
       "      <td>C2706</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>3248</td>\n",
       "      <td>255</td>\n",
       "      <td>12</td>\n",
       "      <td>730</td>\n",
       "      <td>113</td>\n",
       "      <td>725</td>\n",
       "      <td>192</td>\n",
       "      <td>247</td>\n",
       "      <td>193</td>\n",
       "      <td>2724</td>\n",
       "      <td>Commanche</td>\n",
       "      <td>C7756</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>3153</td>\n",
       "      <td>255</td>\n",
       "      <td>12</td>\n",
       "      <td>404</td>\n",
       "      <td>116</td>\n",
       "      <td>2139</td>\n",
       "      <td>192</td>\n",
       "      <td>247</td>\n",
       "      <td>193</td>\n",
       "      <td>994</td>\n",
       "      <td>Commanche</td>\n",
       "      <td>C7756</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Elevation  Aspect  Slope  Horizontal_Distance_To_Hydrology  \\\n",
       "0           2085     256     18                               150   \n",
       "1           2125     256     20                                30   \n",
       "2           2146     256     34                               150   \n",
       "3           2186     256     38                               210   \n",
       "4           2831     256     25                               277   \n",
       "...          ...     ...    ...                               ...   \n",
       "99995       3136     254     12                               319   \n",
       "99996       3242     254     12                               636   \n",
       "99997       2071     255     12                               234   \n",
       "99998       3248     255     12                               730   \n",
       "99999       3153     255     12                               404   \n",
       "\n",
       "       Vertical_Distance_To_Hydrology  Horizontal_Distance_To_Roadways  \\\n",
       "0                                  27                              738   \n",
       "1                                  12                              871   \n",
       "2                                  62                             1253   \n",
       "3                                 102                             1294   \n",
       "4                                 183                             1706   \n",
       "...                               ...                              ...   \n",
       "99995                              60                             5734   \n",
       "99996                             148                             3551   \n",
       "99997                              63                              342   \n",
       "99998                             113                              725   \n",
       "99999                             116                             2139   \n",
       "\n",
       "       Hillshade_9am  Hillshade_Noon  Hillshade_3pm  \\\n",
       "0                176             248            208   \n",
       "1                169             248            215   \n",
       "2                122             237            239   \n",
       "3                109             232            244   \n",
       "4                153             246            225   \n",
       "...              ...             ...            ...   \n",
       "99995            193             248            193   \n",
       "99996            193             248            193   \n",
       "99997            192             247            193   \n",
       "99998            192             247            193   \n",
       "99999            192             247            193   \n",
       "\n",
       "       Horizontal_Distance_To_Fire_Points Wilderness_Area Soil_Type  \\\n",
       "0                                     914           Cache     C2702   \n",
       "1                                     300           Cache     C2702   \n",
       "2                                     511           Cache     C2702   \n",
       "3                                     552           Cache     C2702   \n",
       "4                                    1485       Commanche     C2705   \n",
       "...                                   ...             ...       ...   \n",
       "99995                                2467           Rawah     C7746   \n",
       "99996                                2010       Commanche     C7757   \n",
       "99997                                 247           Cache     C2706   \n",
       "99998                                2724       Commanche     C7756   \n",
       "99999                                 994       Commanche     C7756   \n",
       "\n",
       "       Cover_Type  \n",
       "0               5  \n",
       "1               2  \n",
       "2               2  \n",
       "3               2  \n",
       "4               1  \n",
       "...           ...  \n",
       "99995           1  \n",
       "99996           0  \n",
       "99997           2  \n",
       "99998           1  \n",
       "99999           1  \n",
       "\n",
       "[100000 rows x 13 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "SELECT *\n",
    "FROM `covertype_dataset.covertype`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create training and validation splits\n",
    "\n",
    "Use BigQuery to sample training and validation splits and save them to GCS storage\n",
    "### Create a training split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting on bqjob_r4cfe05c956bb50eb_00000171cd9aa1be_1 ... (2s) Current status: DONE   \n"
     ]
    }
   ],
   "source": [
    "!bq query \\\n",
    "-n 0 \\\n",
    "--destination_table covertype_dataset.training \\\n",
    "--replace \\\n",
    "--use_legacy_sql=false \\\n",
    "'SELECT * \\\n",
    "FROM `covertype_dataset.covertype` AS cover \\\n",
    "WHERE \\\n",
    "MOD(ABS(FARM_FINGERPRINT(TO_JSON_STRING(cover))), 10) IN (1, 2, 3, 4)' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting on bqjob_r1c9da0974cc46a07_00000171cd9ab497_1 ... (0s) Current status: DONE   \n"
     ]
    }
   ],
   "source": [
    "!bq extract \\\n",
    "--destination_format CSV \\\n",
    "covertype_dataset.training \\\n",
    "$TRAINING_FILE_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting on bqjob_r22cb74d9fb203c2a_00000171cd9abeb8_1 ... (1s) Current status: DONE   \n"
     ]
    }
   ],
   "source": [
    "!bq query \\\n",
    "-n 0 \\\n",
    "--destination_table covertype_dataset.validation \\\n",
    "--replace \\\n",
    "--use_legacy_sql=false \\\n",
    "'SELECT * \\\n",
    "FROM `covertype_dataset.covertype` AS cover \\\n",
    "WHERE \\\n",
    "MOD(ABS(FARM_FINGERPRINT(TO_JSON_STRING(cover))), 10) IN (8)' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting on bqjob_r137c248044b38604_00000171cd9acc6e_1 ... (1s) Current status: DONE   \n"
     ]
    }
   ],
   "source": [
    "!bq extract \\\n",
    "--destination_format CSV \\\n",
    "covertype_dataset.validation \\\n",
    "$VALIDATION_FILE_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40009, 13)\n",
      "(9836, 13)\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv(TRAINING_FILE_PATH)\n",
    "df_validation = pd.read_csv(VALIDATION_FILE_PATH)\n",
    "print(df_train.shape)\n",
    "print(df_validation.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Develop a training application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure the `sklearn` training pipeline.\n",
    "\n",
    "The training pipeline preprocesses data by standardizing all numeric features using `sklearn.preprocessing.StandardScaler` and encoding all categorical features using `sklearn.preprocessing.OneHotEncoder`. It uses stochastic gradient descent linear classifier (`SGDClassifier`) for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_feature_indexes = slice(0, 10)\n",
    "categorical_feature_indexes = slice(10, 12)\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_feature_indexes),\n",
    "        ('cat', OneHotEncoder(), categorical_feature_indexes) \n",
    "    ])\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', SGDClassifier(loss='log', tol=1e-3))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert all numeric features to `float64`\n",
    "\n",
    "To avoid warning messages from `StandardScaler` all numeric features are converted to `float64`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features_type_map = {feature: 'float64' for feature in df_train.columns[numeric_feature_indexes]}\n",
    "\n",
    "df_train = df_train.astype(num_features_type_map)\n",
    "df_validation = df_validation.astype(num_features_type_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the pipeline locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('preprocessor',\n",
       "                 ColumnTransformer(n_jobs=None, remainder='drop',\n",
       "                                   sparse_threshold=0.3,\n",
       "                                   transformer_weights=None,\n",
       "                                   transformers=[('num',\n",
       "                                                  StandardScaler(copy=True,\n",
       "                                                                 with_mean=True,\n",
       "                                                                 with_std=True),\n",
       "                                                  slice(0, 10, None)),\n",
       "                                                 ('cat',\n",
       "                                                  OneHotEncoder(categorical_features=None,\n",
       "                                                                categories=None,\n",
       "                                                                drop=None,\n",
       "                                                                dtype=<class 'numpy.float64'>,\n",
       "                                                                handle_unknown='e...\n",
       "                ('classifier',\n",
       "                 SGDClassifier(alpha=0.001, average=False, class_weight=None,\n",
       "                               early_stopping=False, epsilon=0.1, eta0=0.0,\n",
       "                               fit_intercept=True, l1_ratio=0.15,\n",
       "                               learning_rate='optimal', loss='log',\n",
       "                               max_iter=200, n_iter_no_change=5, n_jobs=None,\n",
       "                               penalty='l2', power_t=0.5, random_state=None,\n",
       "                               shuffle=True, tol=0.001, validation_fraction=0.1,\n",
       "                               verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = df_train.drop('Cover_Type', axis=1)\n",
    "y_train = df_train['Cover_Type']\n",
    "X_validation = df_validation.drop('Cover_Type', axis=1)\n",
    "y_validation = df_validation['Cover_Type']\n",
    "\n",
    "pipeline.set_params(classifier__alpha=0.001, classifier__max_iter=200)\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the trained model's accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6968279788531924\n"
     ]
    }
   ],
   "source": [
    "accuracy = pipeline.score(X_validation, y_validation)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcs_model_path = '%s/model/' % ARTIFACT_STORE\n",
    "local_model_path = '/tmp/model.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file:///tmp/model.pkl [Content-Type=application/octet-stream]...\n",
      "/ [1 files][  6.2 KiB/  6.2 KiB]                                                \n",
      "Operation completed over 1 objects/6.2 KiB.                                      \n",
      "gs://mlops-dev-env-staging/model/model.pkl\n"
     ]
    }
   ],
   "source": [
    "with open(local_model_path, 'wb') as model_file:\n",
    "            pickle.dump(pipeline, model_file)\n",
    "        \n",
    "!gsutil cp {local_model_path} {gcs_model_path}\n",
    "!gsutil ls {gcs_model_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy the model to AI Platform Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a model resource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: forest_cover_classifier already exists.\n"
     ]
    }
   ],
   "source": [
    "model_name = 'forest_cover_classifier'\n",
    "labels = \"task=classifier,domain=forestry\"\n",
    "filter = 'name:{}'.format(model_name)\n",
    "models = !(gcloud ai-platform models list --filter={filter} --format='value(name)')\n",
    "\n",
    "if not models:\n",
    "    !gcloud ai-platform models create  $model_name \\\n",
    "    --regions=$REGION \\\n",
    "    --labels=$labels\n",
    "else:\n",
    "    print(\"Model: {} already exists.\".format(models[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a model version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating version (this might take a few minutes)......done.                    \n"
     ]
    }
   ],
   "source": [
    "model_version = 'v01'\n",
    "filter = 'name:{}'.format(model_version)\n",
    "versions = !(gcloud ai-platform versions list --model={model_name} --format='value(name)' --filter={filter})\n",
    "\n",
    "if not versions:\n",
    "    !gcloud ai-platform versions create {model_version} \\\n",
    "    --model={model_name} \\\n",
    "    --origin={gcs_model_path} \\\n",
    "    --runtime-version=1.15 \\\n",
    "    --framework=scikit-learn \\\n",
    "    --python-version=3.7\n",
    "else:\n",
    "    print(\"Model version: {} already exists.\".format(versions[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define predict function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Service name: projects/mlops-dev-env/models/forest_cover_classifier/versions/v01\n"
     ]
    }
   ],
   "source": [
    "service = discovery.build('ml', 'v1')\n",
    "name = 'projects/{}/models/{}/versions/{}'.format(PROJECT_ID, model_name, model_version)\n",
    "print(\"Service name: {}\".format(name))\n",
    "\n",
    "def caip_predict(instances):\n",
    "    \n",
    "  request_body={\n",
    "      'instances': instances}\n",
    "\n",
    "  response = service.projects().predict(\n",
    "      name=name,\n",
    "      body=request_body\n",
    "\n",
    "  ).execute()\n",
    "\n",
    "  if 'error' in response:\n",
    "    raise RuntimeError(response['error'])\n",
    "\n",
    "  return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Invoke the service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'predictions': [1, 1, 0]}\n",
      "***\n",
      "{'predictions': [1, 1, 1]}\n",
      "***\n",
      "{'predictions': [1, 1, 0]}\n",
      "***\n",
      "{'predictions': [0, 0, 0]}\n",
      "***\n",
      "{'predictions': [2, 1, 1]}\n",
      "***\n"
     ]
    }
   ],
   "source": [
    "instance_iterator = X_validation.iterrows()\n",
    "\n",
    "for num_calls in range(5):\n",
    "    instances = []\n",
    "    for num_instances in range(3):\n",
    "        instances.append(list(next(instance_iterator)[1].values))\n",
    "    response = caip_predict(instances)\n",
    "    print(response)\n",
    "    print(\"***\")\n",
    "    time.sleep(0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m11-MCflLjFG"
   },
   "source": [
    "## 5. BigQuery logging dataset preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HmWQwyAUdwIW"
   },
   "source": [
    "### 5.1. Create BQ Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ne38zMEKL_Gk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BigQuery Dataset is ready.\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import bigquery\n",
    "\n",
    "client = bigquery.Client(PROJECT_ID)\n",
    "dataset_names = [dataset.dataset_id for dataset in client.list_datasets(PROJECT_ID)]\n",
    "\n",
    "dataset = bigquery.Dataset(\"{}.{}\".format(PROJECT_ID, BQ_DATASET_NAME))\n",
    "dataset.location = \"US\"\n",
    "\n",
    "if BQ_DATASET_NAME not in dataset_names:\n",
    "  dataset = client.create_dataset(dataset)\n",
    "  print(\"Created dataset {}.{}\".format(client.project, dataset.dataset_id))\n",
    "\n",
    "print(\"BigQuery Dataset is ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ieIgLE94PovQ"
   },
   "source": [
    "### 5.2. Create BQ Table\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ima0Dg1UWkRO"
   },
   "source": [
    "#### Table schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TqxS6RQ0T9LG"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "table_schema_json = [\n",
    "  {\n",
    "    \"name\": \"model\", \n",
    "    \"type\": \"STRING\", \n",
    "    \"mode\": \"REQUIRED\"\n",
    "   },\n",
    "   {\n",
    "     \"name\":\"model_version\", \n",
    "     \"type\": \"STRING\", \n",
    "     \"mode\":\"REQUIRED\"\n",
    "  },\n",
    "  {\n",
    "    \"name\":\"time\", \n",
    "    \"type\": \"TIMESTAMP\", \n",
    "    \"mode\": \"REQUIRED\"\n",
    "  },\n",
    "  {\n",
    "    \"name\":\"raw_data\", \n",
    "    \"type\": \"STRING\", \n",
    "    \"mode\": \"REQUIRED\"\n",
    "  },\n",
    "  {\n",
    "    \"name\":\"raw_prediction\", \n",
    "    \"type\": \"STRING\", \n",
    "    \"mode\": \"NULLABLE\"\n",
    "  },\n",
    "  {\n",
    "    \"name\":\"groundtruth\", \n",
    "    \"type\": \"STRING\", \n",
    "    \"mode\": \"NULLABLE\"\n",
    "  },\n",
    "]\n",
    "\n",
    "json.dump(table_schema_json, open('table_schema.json', 'w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "koE5tKouWngb"
   },
   "source": [
    "#### Ceating an ingestion-time partitioned tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SXkoAGEiXRvj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleteing BQ Table: covertype_classifier_logs ...\n"
     ]
    }
   ],
   "source": [
    "table = bigquery.Table(\n",
    "    \"{}.{}.{}\".format(PROJECT_ID, BQ_DATASET_NAME, BQ_TABLE_NAME))\n",
    "\n",
    "table_names = [table.table_id for table in client.list_tables(dataset)]\n",
    "\n",
    "if BQ_TABLE_NAME in table_names:\n",
    "  print(\"Deleteing BQ Table: {} ...\".format(BQ_TABLE_NAME))\n",
    "  client.delete_table(table)\n",
    "\n",
    "# table = client.create_table(table)\n",
    "# table.partition_expiration = 60 * 60 * 24 * 7\n",
    "# print(\"Created table {}.{}.{}\".format(table.project, table.dataset_id, table.table_id))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QnE9GMjbeqXR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 'mlops-dev-env:data_validation.covertype_classifier_logs' successfully created.\n"
     ]
    }
   ],
   "source": [
    "TIME_PARTITION_EXPERIATION = 60 * 60 * 24 * 7 # week\n",
    "\n",
    "!bq mk --table \\\n",
    "  --project_id={PROJECT_ID} \\\n",
    "  --time_partitioning_type=DAY \\\n",
    "  --time_partitioning_expiration {TIME_PARTITION_EXPERIATION} \\\n",
    "  {PROJECT_ID}:{BQ_DATASET_NAME}.{BQ_TABLE_NAME} \\\n",
    "  'table_schema.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RPFM4mW-R3y8"
   },
   "source": [
    "### 5.3. Configre the AI Platform model version to enable request-response logging to BigQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PBkx4i9Rc51W"
   },
   "outputs": [],
   "source": [
    "sampling_percentage = 1.0\n",
    "bq_full_table_name = '{}.{}.{}'.format(PROJECT_ID, BQ_DATASET_NAME, BQ_TABLE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EarF0cmcRZN4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'projects/mlops-dev-env/operations/update_forest_cover_classifier_v01_1588297334182',\n",
       " 'metadata': {'@type': 'type.googleapis.com/google.cloud.ml.v1.OperationMetadata',\n",
       "  'createTime': '2020-05-01T01:42:14Z',\n",
       "  'operationType': 'UPDATE_VERSION',\n",
       "  'modelName': 'projects/mlops-dev-env/models/forest_cover_classifier',\n",
       "  'version': {'name': 'projects/mlops-dev-env/models/forest_cover_classifier/versions/v01',\n",
       "   'deploymentUri': 'gs://mlops-dev-env-staging/model/',\n",
       "   'createTime': '2020-05-01T00:28:16Z',\n",
       "   'runtimeVersion': '1.15',\n",
       "   'state': 'READY',\n",
       "   'etag': 'UStD2oUPU7E=',\n",
       "   'framework': 'SCIKIT_LEARN',\n",
       "   'machineType': 'mls1-c1-m2',\n",
       "   'pythonVersion': '3.7',\n",
       "   'requestLoggingConfig': {'samplingPercentage': 1,\n",
       "    'bigqueryTableName': 'mlops-dev-env.data_validation.covertype_classifier_logs'}}}}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logging_config = {\n",
    "    \"requestLoggingConfig\":{\n",
    "        \"samplingPercentage\": sampling_percentage,\n",
    "        \"bigqueryTableName\": bq_full_table_name\n",
    "        }\n",
    "    }\n",
    "\n",
    "response = service.projects().models().versions().patch(\n",
    "    name=name,\n",
    "    body=logging_config,\n",
    "    updateMask=\"requestLoggingConfig\"\n",
    "    ).execute()\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kVpICSuq0Kp1"
   },
   "source": [
    "### 5.4. Test request-response logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'predictions': [1, 1, 0]}\n",
      "***\n",
      "{'predictions': [1, 1, 1]}\n",
      "***\n",
      "{'predictions': [1, 1, 0]}\n",
      "***\n",
      "{'predictions': [0, 0, 0]}\n",
      "***\n",
      "{'predictions': [2, 1, 1]}\n",
      "***\n",
      "{'predictions': [1, 1, 1]}\n",
      "***\n",
      "{'predictions': [1, 1, 1]}\n",
      "***\n",
      "{'predictions': [0, 1, 1]}\n",
      "***\n",
      "{'predictions': [0, 0, 1]}\n",
      "***\n",
      "{'predictions': [1, 1, 1]}\n",
      "***\n",
      "{'predictions': [1, 1, 1]}\n",
      "***\n",
      "{'predictions': [1, 0, 0]}\n",
      "***\n",
      "{'predictions': [0, 0, 0]}\n",
      "***\n",
      "{'predictions': [0, 0, 1]}\n",
      "***\n",
      "{'predictions': [0, 1, 0]}\n",
      "***\n",
      "{'predictions': [0, 0, 0]}\n",
      "***\n",
      "{'predictions': [1, 0, 0]}\n",
      "***\n",
      "{'predictions': [0, 0, 1]}\n",
      "***\n",
      "{'predictions': [1, 0, 1]}\n",
      "***\n",
      "{'predictions': [1, 1, 1]}\n",
      "***\n",
      "{'predictions': [1, 1, 0]}\n",
      "***\n",
      "{'predictions': [0, 0, 1]}\n",
      "***\n",
      "{'predictions': [0, 1, 1]}\n",
      "***\n",
      "{'predictions': [0, 1, 1]}\n",
      "***\n",
      "{'predictions': [1, 0, 1]}\n",
      "***\n",
      "{'predictions': [1, 0, 1]}\n",
      "***\n",
      "{'predictions': [1, 0, 1]}\n",
      "***\n",
      "{'predictions': [0, 5, 1]}\n",
      "***\n",
      "{'predictions': [1, 1, 1]}\n",
      "***\n",
      "{'predictions': [1, 1, 1]}\n",
      "***\n",
      "{'predictions': [1, 1, 1]}\n",
      "***\n",
      "{'predictions': [1, 1, 1]}\n",
      "***\n",
      "{'predictions': [1, 1, 1]}\n",
      "***\n",
      "{'predictions': [2, 1, 0]}\n",
      "***\n",
      "{'predictions': [0, 0, 1]}\n",
      "***\n",
      "{'predictions': [0, 0, 1]}\n",
      "***\n",
      "{'predictions': [0, 1, 0]}\n",
      "***\n",
      "{'predictions': [1, 1, 1]}\n",
      "***\n",
      "{'predictions': [0, 0, 0]}\n",
      "***\n",
      "{'predictions': [0, 0, 0]}\n",
      "***\n",
      "{'predictions': [0, 0, 0]}\n",
      "***\n",
      "{'predictions': [0, 0, 0]}\n",
      "***\n",
      "{'predictions': [0, 0, 0]}\n",
      "***\n",
      "{'predictions': [0, 0, 0]}\n",
      "***\n",
      "{'predictions': [0, 0, 0]}\n",
      "***\n",
      "{'predictions': [0, 0, 0]}\n",
      "***\n",
      "{'predictions': [1, 1, 0]}\n",
      "***\n",
      "{'predictions': [0, 0, 0]}\n",
      "***\n",
      "{'predictions': [1, 0, 0]}\n",
      "***\n",
      "{'predictions': [0, 1, 0]}\n",
      "***\n",
      "{'predictions': [1, 1, 0]}\n",
      "***\n",
      "{'predictions': [1, 0, 1]}\n",
      "***\n",
      "{'predictions': [0, 0, 1]}\n",
      "***\n",
      "{'predictions': [1, 1, 1]}\n",
      "***\n",
      "{'predictions': [1, 0, 0]}\n",
      "***\n",
      "{'predictions': [1, 1, 0]}\n",
      "***\n",
      "{'predictions': [1, 1, 1]}\n",
      "***\n",
      "{'predictions': [1, 0, 1]}\n",
      "***\n",
      "{'predictions': [1, 1, 1]}\n",
      "***\n",
      "{'predictions': [1, 1, 0]}\n",
      "***\n",
      "{'predictions': [1, 0, 0]}\n",
      "***\n",
      "{'predictions': [1, 1, 6]}\n",
      "***\n",
      "{'predictions': [0, 0, 0]}\n",
      "***\n",
      "{'predictions': [6, 0, 0]}\n",
      "***\n",
      "{'predictions': [0, 0, 0]}\n",
      "***\n",
      "{'predictions': [0, 2, 2]}\n",
      "***\n",
      "{'predictions': [2, 1, 1]}\n",
      "***\n",
      "{'predictions': [1, 1, 1]}\n",
      "***\n",
      "{'predictions': [1, 1, 1]}\n",
      "***\n",
      "{'predictions': [1, 1, 1]}\n",
      "***\n",
      "{'predictions': [1, 1, 1]}\n",
      "***\n",
      "{'predictions': [1, 1, 1]}\n",
      "***\n",
      "{'predictions': [1, 1, 1]}\n",
      "***\n",
      "{'predictions': [1, 1, 1]}\n",
      "***\n",
      "{'predictions': [1, 1, 1]}\n",
      "***\n",
      "{'predictions': [1, 1, 0]}\n",
      "***\n",
      "{'predictions': [1, 5, 1]}\n",
      "***\n",
      "{'predictions': [1, 1, 1]}\n",
      "***\n",
      "{'predictions': [1, 1, 0]}\n",
      "***\n",
      "{'predictions': [1, 0, 0]}\n",
      "***\n",
      "{'predictions': [0, 0, 0]}\n",
      "***\n",
      "{'predictions': [1, 0, 1]}\n",
      "***\n",
      "{'predictions': [1, 1, 1]}\n",
      "***\n",
      "{'predictions': [0, 0, 0]}\n",
      "***\n",
      "{'predictions': [0, 0, 0]}\n",
      "***\n",
      "{'predictions': [0, 0, 0]}\n",
      "***\n",
      "{'predictions': [0, 0, 0]}\n",
      "***\n",
      "{'predictions': [0, 0, 0]}\n",
      "***\n",
      "{'predictions': [0, 0, 0]}\n",
      "***\n",
      "{'predictions': [0, 0, 0]}\n",
      "***\n",
      "{'predictions': [1, 0, 1]}\n",
      "***\n",
      "{'predictions': [0, 0, 0]}\n",
      "***\n",
      "{'predictions': [0, 0, 1]}\n",
      "***\n",
      "{'predictions': [0, 0, 1]}\n",
      "***\n",
      "{'predictions': [0, 1, 0]}\n",
      "***\n",
      "{'predictions': [0, 0, 0]}\n",
      "***\n",
      "{'predictions': [0, 1, 0]}\n",
      "***\n",
      "{'predictions': [0, 0, 1]}\n",
      "***\n",
      "{'predictions': [1, 0, 0]}\n",
      "***\n",
      "{'predictions': [0, 0, 0]}\n",
      "***\n"
     ]
    }
   ],
   "source": [
    "instance_iterator = X_validation.iterrows()\n",
    "\n",
    "for num_calls in range(100):\n",
    "    instances = []\n",
    "    for num_instances in range(3):\n",
    "        instances.append(list(next(instance_iterator)[1].values))\n",
    "    response = caip_predict(instances)\n",
    "    print(response)\n",
    "    print(\"***\")\n",
    "    time.sleep(0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jdlrKX0d0mQC"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 3/3 [00:00<00:00, 18.63rows/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <td>forest_cover_classifier</td>\n",
       "      <td>forest_cover_classifier</td>\n",
       "      <td>forest_cover_classifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_version</th>\n",
       "      <td>v01</td>\n",
       "      <td>v01</td>\n",
       "      <td>v01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <td>2020-05-01 01:44:53+00:00</td>\n",
       "      <td>2020-05-01 01:44:52+00:00</td>\n",
       "      <td>2020-05-01 01:44:52+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>raw_data</th>\n",
       "      <td>{\"instances\": [[3086.0, 308.0, 3.0, 295.0, 43....</td>\n",
       "      <td>{\"instances\": [[3192.0, 21.0, 3.0, 210.0, 33.0...</td>\n",
       "      <td>{\"instances\": [[2788.0, 22.0, 3.0, 30.0, -1.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>raw_prediction</th>\n",
       "      <td>{\"predictions\": [0, 0, 0]}</td>\n",
       "      <td>{\"predictions\": [0, 0, 1]}</td>\n",
       "      <td>{\"predictions\": [1, 0, 0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>groundtruth</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                0  \\\n",
       "model                                     forest_cover_classifier   \n",
       "model_version                                                 v01   \n",
       "time                                    2020-05-01 01:44:53+00:00   \n",
       "raw_data        {\"instances\": [[3086.0, 308.0, 3.0, 295.0, 43....   \n",
       "raw_prediction                         {\"predictions\": [0, 0, 0]}   \n",
       "groundtruth                                                  None   \n",
       "\n",
       "                                                                1  \\\n",
       "model                                     forest_cover_classifier   \n",
       "model_version                                                 v01   \n",
       "time                                    2020-05-01 01:44:52+00:00   \n",
       "raw_data        {\"instances\": [[3192.0, 21.0, 3.0, 210.0, 33.0...   \n",
       "raw_prediction                         {\"predictions\": [0, 0, 1]}   \n",
       "groundtruth                                                  None   \n",
       "\n",
       "                                                                2  \n",
       "model                                     forest_cover_classifier  \n",
       "model_version                                                 v01  \n",
       "time                                    2020-05-01 01:44:52+00:00  \n",
       "raw_data        {\"instances\": [[2788.0, 22.0, 3.0, 30.0, -1.0,...  \n",
       "raw_prediction                         {\"predictions\": [1, 0, 0]}  \n",
       "groundtruth                                                  None  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = '''\n",
    "  SELECT * FROM \n",
    "  `{}.{}` \n",
    "  WHERE model_version = '{}'\n",
    "  ORDER BY time desc\n",
    "  LIMIT {}\n",
    "'''.format(BQ_DATASET_NAME, BQ_TABLE_NAME, model_version, 3)\n",
    "\n",
    "pd.io.gbq.read_gbq(\n",
    "    query, project_id=PROJECT_ID).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=-1>Licensed under the Apache License, Version 2.0 (the \\\"License\\\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at [https://www.apache.org/licenses/LICENSE-2.0](https://www.apache.org/licenses/LICENSE-2.0)\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \\\"AS IS\\\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the License for the specific language governing permissions and limitations under the License.</font>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
